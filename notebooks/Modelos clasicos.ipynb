{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a250113-65e1-48aa-b404-23da1ef4917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ“ LibrerÃ­as importadas correctamente\")\n",
    "print(f\"âœ“ PyTorch version: {torch.__version__}\")\n",
    "print(f\"âœ“ CUDA disponible: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3500f1-f8dd-4f56-a0a1-dff75bc916cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=1111):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print(f\"âœ“ Seed fijado en {seed}\")\n",
    "\n",
    "set_seed(1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e845d100-cc09-45ce-80bc-f34be1a7da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=6, dilation=6, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=12, dilation=12, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=18, dilation=18, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.pool = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_ch, out_ch, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(out_ch * 5, out_ch, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        size = x.shape[2:]\n",
    "        feat1 = self.conv1(x)\n",
    "        feat2 = self.conv2(x)\n",
    "        feat3 = self.conv3(x)\n",
    "        feat4 = self.conv4(x)\n",
    "        feat5 = F.interpolate(self.pool(x), size=size, mode='bilinear', align_corners=True)\n",
    "        out = torch.cat([feat1, feat2, feat3, feat4, feat5], dim=1)\n",
    "        return self.project(out)\n",
    "\n",
    "class PyramidPooling(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, sizes=(1, 2, 3, 6)):\n",
    "        super().__init__()\n",
    "        self.stages = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(size),\n",
    "                nn.Conv2d(in_ch, out_ch, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ) for size in sizes\n",
    "        ])\n",
    "        \n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(in_ch + len(sizes) * out_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h, w = x.shape[2:]\n",
    "        pyramids = [x]\n",
    "        for stage in self.stages:\n",
    "            pyramids.append(F.interpolate(stage(x), size=(h, w), mode='bilinear', align_corners=True))\n",
    "        return self.bottleneck(torch.cat(pyramids, dim=1))\n",
    "\n",
    "print(\"âœ“ MÃ³dulos base definidos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c5e712-4e32-4a46-a0ed-219a1589a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabV3Plus(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.enc1 = ConvBlock(in_channels, 64)\n",
    "        self.enc2 = ConvBlock(64, 128)\n",
    "        self.enc3 = ConvBlock(128, 256)\n",
    "        self.enc4 = ConvBlock(256, 512)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.aspp = ASPP(512, 256)\n",
    "        \n",
    "        self.decoder_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 48, 1, bias=False),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.decoder_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(256 + 48, 256, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Conv2d(256, num_classes, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        size = x.shape[2:]\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(self.pool(enc1))\n",
    "        enc3 = self.enc3(self.pool(enc2))\n",
    "        enc4 = self.enc4(self.pool(enc3))\n",
    "        \n",
    "        aspp_out = self.aspp(enc4)\n",
    "        low_level = self.decoder_conv1(enc1)\n",
    "        aspp_up = F.interpolate(aspp_out, size=low_level.shape[2:], mode='bilinear', align_corners=True)\n",
    "        dec = torch.cat([aspp_up, low_level], dim=1)\n",
    "        dec = self.decoder_conv2(dec)\n",
    "        out = F.interpolate(dec, size=size, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        return self.out(out)\n",
    "\n",
    "class LinkNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.enc1 = ConvBlock(in_channels, 64)\n",
    "        self.enc2 = ConvBlock(64, 128)\n",
    "        self.enc3 = ConvBlock(128, 256)\n",
    "        self.enc4 = ConvBlock(256, 512)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.dec4 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.dec3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Conv2d(64, num_classes, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        size = x.shape[2:]\n",
    "        \n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(self.pool(enc1))\n",
    "        enc3 = self.enc3(self.pool(enc2))\n",
    "        enc4 = self.enc4(self.pool(enc3))\n",
    "        \n",
    "        dec4 = self.dec4(enc4)\n",
    "        dec4 = F.interpolate(dec4, size=enc3.shape[2:], mode='bilinear', align_corners=True)\n",
    "        dec4 = dec4 + enc3\n",
    "        \n",
    "        dec3 = self.dec3(dec4)\n",
    "        dec3 = F.interpolate(dec3, size=enc2.shape[2:], mode='bilinear', align_corners=True)\n",
    "        dec3 = dec3 + enc2\n",
    "        \n",
    "        dec2 = self.dec2(dec3)\n",
    "        dec2 = F.interpolate(dec2, size=enc1.shape[2:], mode='bilinear', align_corners=True)\n",
    "        dec2 = dec2 + enc1\n",
    "        \n",
    "        dec1 = self.dec1(dec2)\n",
    "        out = self.out(dec1)\n",
    "        \n",
    "        if out.shape[2:] != size:\n",
    "            out = F.interpolate(out, size=size, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        return out\n",
    "\n",
    "print(\"âœ“ DeepLabV3+ y LinkNet definidos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b384acd9-8bc5-4da7-872a-cec81a029d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.enc1 = ConvBlock(in_channels, 64)\n",
    "        self.enc2 = ConvBlock(64, 128)\n",
    "        self.enc3 = ConvBlock(128, 256)\n",
    "        self.enc4 = ConvBlock(256, 512)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.psp = PyramidPooling(512, 128, sizes=(1, 2, 3, 6))\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec3 = ConvBlock(320, 256)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.dec2 = ConvBlock(256, 128)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = ConvBlock(128, 64)\n",
    "        \n",
    "        self.out = nn.Conv2d(64, num_classes, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        size = x.shape[2:]\n",
    "        \n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        e4 = self.enc4(self.pool(e3))\n",
    "        \n",
    "        psp_out = self.psp(e4)\n",
    "        \n",
    "        d3 = self.up3(psp_out)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "        \n",
    "        d2 = self.up2(d3)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "        \n",
    "        d1 = self.up1(d2)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "        \n",
    "        out = self.out(d1)\n",
    "        if out.shape[2:] != size:\n",
    "            out = F.interpolate(out, size=size, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class UNetPlusPlus(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv0_0 = ConvBlock(in_channels, 64)\n",
    "        self.conv1_0 = ConvBlock(64, 128)\n",
    "        self.conv2_0 = ConvBlock(128, 256)\n",
    "        self.conv3_0 = ConvBlock(256, 512)\n",
    "        self.conv4_0 = ConvBlock(512, 1024)\n",
    "        \n",
    "        self.conv0_1 = ConvBlock(64 + 128, 64)\n",
    "        self.conv1_1 = ConvBlock(128 + 256, 128)\n",
    "        self.conv2_1 = ConvBlock(256 + 512, 256)\n",
    "        self.conv3_1 = ConvBlock(512 + 1024, 512)\n",
    "        \n",
    "        self.conv0_2 = ConvBlock(64 * 2 + 128, 64)\n",
    "        self.conv1_2 = ConvBlock(128 * 2 + 256, 128)\n",
    "        self.conv2_2 = ConvBlock(256 * 2 + 512, 256)\n",
    "        \n",
    "        self.conv0_3 = ConvBlock(64 * 3 + 128, 64)\n",
    "        self.conv1_3 = ConvBlock(128 * 3 + 256, 128)\n",
    "        \n",
    "        self.conv0_4 = ConvBlock(64 * 4 + 128, 64)\n",
    "        \n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.out = nn.Conv2d(64, num_classes, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x0_0 = self.conv0_0(x)\n",
    "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
    "        x0_1 = self.conv0_1(torch.cat([x0_0, self.up(x1_0)], 1))\n",
    "        \n",
    "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
    "        x1_1 = self.conv1_1(torch.cat([x1_0, self.up(x2_0)], 1))\n",
    "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up(x1_1)], 1))\n",
    "        \n",
    "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
    "        x2_1 = self.conv2_1(torch.cat([x2_0, self.up(x3_0)], 1))\n",
    "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up(x2_1)], 1))\n",
    "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.up(x1_2)], 1))\n",
    "        \n",
    "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
    "        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))\n",
    "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up(x3_1)], 1))\n",
    "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], 1))\n",
    "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], 1))\n",
    "        \n",
    "        return self.out(x0_4)\n",
    "\n",
    "print(\"âœ“ PSPNet y U-Net++ definidos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb85d38-6ce5-42fd-bf1f-bbc719b1e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation Block\"\"\"\n",
    "    def __init__(self, channels, reduction=4):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Hardsigmoid(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.shape\n",
    "        y = self.pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "class MobileNetV3Block(nn.Module):\n",
    "    \"\"\"MobileNetV3 Inverted Residual Block\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, exp_size, use_se=False, use_hs=False):\n",
    "        super().__init__()\n",
    "        self.stride = stride\n",
    "        self.use_residual = (stride == 1 and in_channels == out_channels)\n",
    "        \n",
    "        activation = nn.Hardswish if use_hs else nn.ReLU\n",
    "        \n",
    "        layers = []\n",
    "        if exp_size != in_channels:\n",
    "            layers.extend([\n",
    "                nn.Conv2d(in_channels, exp_size, 1, bias=False),\n",
    "                nn.BatchNorm2d(exp_size),\n",
    "                activation(inplace=True)\n",
    "            ])\n",
    "        \n",
    "        layers.extend([\n",
    "            nn.Conv2d(exp_size, exp_size, kernel_size, stride=stride, \n",
    "                     padding=kernel_size//2, groups=exp_size, bias=False),\n",
    "            nn.BatchNorm2d(exp_size),\n",
    "            activation(inplace=True)\n",
    "        ])\n",
    "        \n",
    "        if use_se:\n",
    "            layers.append(SEBlock(exp_size))\n",
    "        \n",
    "        layers.extend([\n",
    "            nn.Conv2d(exp_size, out_channels, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        ])\n",
    "        \n",
    "        self.conv = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.use_residual:\n",
    "            return x + self.conv(x)\n",
    "        return self.conv(x)\n",
    "\n",
    "class MobileNetV3SmallEncoder(nn.Module):\n",
    "    \"\"\"MobileNetV3-Small como Encoder\"\"\"\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Stem\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 16, 3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Hardswish(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Stage 1\n",
    "        self.stage1 = nn.Sequential(\n",
    "            MobileNetV3Block(16, 16, 3, 2, 16, use_se=True, use_hs=False)\n",
    "        )\n",
    "        \n",
    "        # Stage 2\n",
    "        self.stage2 = nn.Sequential(\n",
    "            MobileNetV3Block(16, 24, 3, 2, 72, use_se=False, use_hs=False),\n",
    "            MobileNetV3Block(24, 24, 3, 1, 88, use_se=False, use_hs=False)\n",
    "        )\n",
    "        \n",
    "        # Stage 3\n",
    "        self.stage3 = nn.Sequential(\n",
    "            MobileNetV3Block(24, 40, 5, 2, 96, use_se=True, use_hs=True),\n",
    "            MobileNetV3Block(40, 40, 5, 1, 240, use_se=True, use_hs=True),\n",
    "            MobileNetV3Block(40, 40, 5, 1, 240, use_se=True, use_hs=True)\n",
    "        )\n",
    "        \n",
    "        # Stage 4\n",
    "        self.stage4 = nn.Sequential(\n",
    "            MobileNetV3Block(40, 48, 5, 1, 120, use_se=True, use_hs=True),\n",
    "            MobileNetV3Block(48, 48, 5, 1, 144, use_se=True, use_hs=True)\n",
    "        )\n",
    "        \n",
    "        # Stage 5\n",
    "        self.stage5 = nn.Sequential(\n",
    "            MobileNetV3Block(48, 96, 5, 2, 288, use_se=True, use_hs=True),\n",
    "            MobileNetV3Block(96, 96, 5, 1, 576, use_se=True, use_hs=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x0 = self.stem(x)      # 1/2\n",
    "        x1 = self.stage1(x0)   # 1/4\n",
    "        x2 = self.stage2(x1)   # 1/8\n",
    "        x3 = self.stage3(x2)   # 1/16\n",
    "        x4 = self.stage4(x3)   # 1/16\n",
    "        x5 = self.stage5(x4)   # 1/32\n",
    "        \n",
    "        return [x1, x2, x3, x5]  # Skip connections\n",
    "\n",
    "class SimpleUNetDecoder(nn.Module):\n",
    "    \"\"\"Decoder U-Net Simplificado\"\"\"\n",
    "    def __init__(self, encoder_channels=[16, 24, 40, 96]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Bloques de upsampling\n",
    "        self.up4 = nn.ConvTranspose2d(encoder_channels[3], 64, 2, stride=2)\n",
    "        self.dec4 = nn.Sequential(\n",
    "            nn.Conv2d(64 + encoder_channels[2], 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
    "        self.dec3 = nn.Sequential(\n",
    "            nn.Conv2d(32 + encoder_channels[1], 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(32, 16, 2, stride=2)\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(16 + encoder_channels[0], 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(16, 16, 2, stride=2)\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, features):\n",
    "        x1, x2, x3, x5 = features\n",
    "        \n",
    "        d4 = self.up4(x5)\n",
    "        d4 = torch.cat([d4, x3], dim=1)\n",
    "        d4 = self.dec4(d4)\n",
    "        \n",
    "        d3 = self.up3(d4)\n",
    "        d3 = torch.cat([d3, x2], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "        \n",
    "        d2 = self.up2(d3)\n",
    "        d2 = torch.cat([d2, x1], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "        \n",
    "        d1 = self.up1(d2)\n",
    "        out = self.final(d1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class ConvClassifier(nn.Module):\n",
    "    \"\"\"Clasificador Convolucional\"\"\"\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels, num_classes, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "class MobileNetV3UNet(nn.Module):\n",
    "    \"\"\"MobileNetV3-Small + U-Net Simple + Clasificador CNN\"\"\"\n",
    "    def __init__(self, in_channels=3, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.encoder = MobileNetV3SmallEncoder(in_channels)\n",
    "        self.decoder = SimpleUNetDecoder(encoder_channels=[16, 24, 40, 96])\n",
    "        self.classifier = ConvClassifier(16, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        input_size = x.shape[2:]\n",
    "        \n",
    "        # Encoder extrae caracterÃ­sticas\n",
    "        features = self.encoder(x)\n",
    "        \n",
    "        # Decoder localiza vÃ©rtebras\n",
    "        decoded = self.decoder(features)\n",
    "        \n",
    "        # Clasificador predice clases\n",
    "        out = self.classifier(decoded)\n",
    "        \n",
    "        # Ajustar a tamaÃ±o original si es necesario\n",
    "        if out.shape[2:] != input_size:\n",
    "            out = F.interpolate(out, size=input_size, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        return out\n",
    "\n",
    "print(\"âœ“ MobileNetV3-UNet definido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0067cbcf-e769-425d-8e25-37d0929aa0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileViTBlock(nn.Module):\n",
    "    \"\"\"MobileViT Block: Conv + Transformer + Conv\"\"\"\n",
    "    def __init__(self, in_channels, transformer_dim, num_heads=4, num_layers=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Local representation (conv)\n",
    "        self.local_rep = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 3, padding=1, groups=in_channels),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv2d(in_channels, transformer_dim, 1),\n",
    "            nn.BatchNorm2d(transformer_dim),\n",
    "            nn.SiLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Global representation (transformer)\n",
    "        self.transformer = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=transformer_dim,\n",
    "                nhead=num_heads,\n",
    "                dim_feedforward=transformer_dim * 2,\n",
    "                dropout=0.0,\n",
    "                activation='gelu',\n",
    "                batch_first=True\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Fusion\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Conv2d(transformer_dim, in_channels, 1),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.SiLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Local representation\n",
    "        local_feat = self.local_rep(x)\n",
    "        B, C, H, W = local_feat.shape\n",
    "        \n",
    "        # Reshape para transformer\n",
    "        transformer_input = local_feat.flatten(2).transpose(1, 2)  # B, H*W, C\n",
    "        \n",
    "        # Global representation\n",
    "        global_feat = transformer_input\n",
    "        for layer in self.transformer:\n",
    "            global_feat = layer(global_feat)\n",
    "        \n",
    "        # Reshape de vuelta\n",
    "        global_feat = global_feat.transpose(1, 2).reshape(B, C, H, W)\n",
    "        \n",
    "        # Fusion\n",
    "        out = self.fusion(global_feat)\n",
    "        \n",
    "        return x + out  # Residual connection\n",
    "\n",
    "class MobileViTXSmallEncoder(nn.Module):\n",
    "    \"\"\"MobileViT-XSmall como Encoder\"\"\"\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Stem\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 16, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.SiLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Stage 1: MV2 blocks (1/4 resolution)\n",
    "        self.stage1 = nn.Sequential(\n",
    "            MobileNetV3Block(16, 16, 3, 1, 32, use_se=False, use_hs=False),\n",
    "            MobileNetV3Block(16, 24, 3, 2, 48, use_se=False, use_hs=False)\n",
    "        )\n",
    "        \n",
    "        # Stage 2: MV2 + MobileViT (1/8 resolution)\n",
    "        self.stage2_conv = MobileNetV3Block(24, 32, 3, 2, 64, use_se=False, use_hs=False)\n",
    "        self.stage2_vit = MobileViTBlock(32, transformer_dim=64, num_heads=4, num_layers=2)\n",
    "        \n",
    "        # Stage 3: MV2 blocks (1/16 resolution)\n",
    "        self.stage3 = nn.Sequential(\n",
    "            MobileNetV3Block(32, 48, 3, 2, 96, use_se=True, use_hs=True),\n",
    "            MobileNetV3Block(48, 48, 3, 1, 128, use_se=True, use_hs=True)\n",
    "        )\n",
    "        \n",
    "        # Stage 4: MV2 + MobileViT (1/32 resolution)\n",
    "        self.stage4_conv = MobileNetV3Block(48, 64, 3, 2, 160, use_se=True, use_hs=True)\n",
    "        self.stage4_vit = MobileViTBlock(64, transformer_dim=80, num_heads=4, num_layers=2)\n",
    "        \n",
    "        # Stage 5: Final conv (1/32 resolution)\n",
    "        self.stage5 = nn.Sequential(\n",
    "            MobileNetV3Block(64, 80, 3, 1, 256, use_se=True, use_hs=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: 256x256\n",
    "        x0 = self.stem(x)           # 128x128\n",
    "        \n",
    "        x1 = self.stage1(x0)        # 64x64\n",
    "        \n",
    "        x2 = self.stage2_conv(x1)   # 32x32\n",
    "        x2 = self.stage2_vit(x2)    # 32x32 con atenciÃ³n\n",
    "        \n",
    "        x3 = self.stage3(x2)        # 16x16\n",
    "        \n",
    "        x4 = self.stage4_conv(x3)   # 8x8\n",
    "        x4 = self.stage4_vit(x4)    # 8x8 con atenciÃ³n\n",
    "        \n",
    "        x5 = self.stage5(x4)        # 8x8\n",
    "        \n",
    "        return [x1, x2, x3, x5]  # Skip connections: 64x64, 32x32, 16x16, 8x8\n",
    "\n",
    "class SimplifiedDecoder(nn.Module):\n",
    "    \"\"\"Decoder Simplificado para MobileViT\"\"\"\n",
    "    def __init__(self, encoder_channels=[24, 32, 48, 80]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Upsampling progresivo con interpolaciÃ³n para manejar mejor las dimensiones\n",
    "        # De 8x8 a 16x16\n",
    "        self.up4 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(encoder_channels[3], 48, 3, padding=1),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # DespuÃ©s de concatenar: 48 + 48 = 96 canales\n",
    "        self.dec4 = nn.Sequential(\n",
    "            nn.Conv2d(96, 48, 3, padding=1),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # De 16x16 a 32x32\n",
    "        self.up3 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(48, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # DespuÃ©s de concatenar: 32 + 32 = 64 canales\n",
    "        self.dec3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # De 32x32 a 64x64\n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(32, 24, 3, padding=1),\n",
    "            nn.BatchNorm2d(24),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # DespuÃ©s de concatenar: 24 + 24 = 48 canales\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(48, 24, 3, padding=1),\n",
    "            nn.BatchNorm2d(24),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # De 64x64 a 128x128\n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(24, 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # De 128x128 a 256x256\n",
    "        self.final_up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(16, 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, features):\n",
    "        x1, x2, x3, x5 = features  # 64x64 (24ch), 32x32 (32ch), 16x16 (48ch), 8x8 (80ch)\n",
    "        \n",
    "        # 8x8 -> 16x16\n",
    "        d4 = self.up4(x5)  # 80 -> 48 canales\n",
    "        # Asegurar dimensiones compatibles\n",
    "        if d4.shape[2:] != x3.shape[2:]:\n",
    "            d4 = F.interpolate(d4, size=x3.shape[2:], mode='bilinear', align_corners=True)\n",
    "        d4 = torch.cat([d4, x3], dim=1)  # 48 + 48 = 96\n",
    "        d4 = self.dec4(d4)  # 96 -> 48\n",
    "        \n",
    "        # 16x16 -> 32x32\n",
    "        d3 = self.up3(d4)  # 48 -> 32 canales\n",
    "        if d3.shape[2:] != x2.shape[2:]:\n",
    "            d3 = F.interpolate(d3, size=x2.shape[2:], mode='bilinear', align_corners=True)\n",
    "        d3 = torch.cat([d3, x2], dim=1)  # 32 + 32 = 64\n",
    "        d3 = self.dec3(d3)  # 64 -> 32\n",
    "        \n",
    "        # 32x32 -> 64x64\n",
    "        d2 = self.up2(d3)  # 32 -> 24 canales\n",
    "        if d2.shape[2:] != x1.shape[2:]:\n",
    "            d2 = F.interpolate(d2, size=x1.shape[2:], mode='bilinear', align_corners=True)\n",
    "        d2 = torch.cat([d2, x1], dim=1)  # 24 + 24 = 48\n",
    "        d2 = self.dec2(d2)  # 48 -> 24\n",
    "        \n",
    "        # 64x64 -> 128x128\n",
    "        d1 = self.up1(d2)  # 24 -> 16\n",
    "        \n",
    "        # 128x128 -> 256x256\n",
    "        out = self.final_up(d1)  # 16 -> 16\n",
    "        \n",
    "        return out\n",
    "\n",
    "class MobileViTXSmall(nn.Module):\n",
    "    \"\"\"MobileViT-XSmall + Decoder Simplificado + Clasificador CNN\"\"\"\n",
    "    def __init__(self, in_channels=3, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.encoder = MobileViTXSmallEncoder(in_channels)\n",
    "        self.decoder = SimplifiedDecoder(encoder_channels=[24, 24, 48, 80])\n",
    "        self.classifier = ConvClassifier(16, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        input_size = x.shape[2:]\n",
    "        \n",
    "        # Encoder: convoluciones capturan detalles + atenciÃ³n captura contexto\n",
    "        features = self.encoder(x)\n",
    "        \n",
    "        # Decoder localiza vÃ©rtebras\n",
    "        decoded = self.decoder(features)\n",
    "        \n",
    "        # Clasificador predice clases\n",
    "        out = self.classifier(decoded)\n",
    "        \n",
    "        # Ajustar a tamaÃ±o original si es necesario\n",
    "        if out.shape[2:] != input_size:\n",
    "            out = F.interpolate(out, size=input_size, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        return out\n",
    "\n",
    "print(\"âœ“ MobileViT-XSmall definido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f675dc40-96d4-460e-a449-fdc552f011ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VertebrasDataset(Dataset):\n",
    "    def __init__(self, base_path, json_filename='coco_anotaciones_actualizadas_23sep.json',\n",
    "                 target_size=(256, 256)):\n",
    "        \n",
    "        self.base_path = Path(base_path)\n",
    "        self.json_path = self.base_path / \"Anotaciones vÃ©rtebras\" / json_filename\n",
    "        self.radiografias_path = self.base_path / \"RadiografÃ­as\"\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        with open(self.json_path, 'r', encoding='utf-8') as f:\n",
    "            self.coco_data = json.load(f)\n",
    "        \n",
    "        self.class_names = ['Background', 'T1', 'V']\n",
    "        \n",
    "        self.name_to_class = {\n",
    "            'F': 0,\n",
    "            'background': 0,\n",
    "            'T1': 1,\n",
    "            'V': 2\n",
    "        }\n",
    "        \n",
    "        self.samples = self._preparar_samples()\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.399637, 0.400040, 0.392532],\n",
    "                std=[0.212403, 0.211738, 0.207753]\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        print(f\"âœ“ Clases definidas: {self.class_names}\")\n",
    "        print(f\"âœ“ Mapeo de nombres: {self.name_to_class}\")\n",
    "    \n",
    "    def _preparar_samples(self):\n",
    "        samples = []\n",
    "        anns_por_imagen = defaultdict(list)\n",
    "        \n",
    "        for ann in self.coco_data['annotations']:\n",
    "            img_id = ann.get('image_id')\n",
    "            if img_id is not None:\n",
    "                anns_por_imagen[img_id].append(ann)\n",
    "        \n",
    "        for img_info in self.coco_data['images']:\n",
    "            img_id = img_info.get('id')\n",
    "            if img_id not in anns_por_imagen:\n",
    "                continue\n",
    "            \n",
    "            file_name = img_info.get('file_name') or img_info.get('toras_path', '') or ''\n",
    "            if file_name.startswith('/'):\n",
    "                file_name = file_name[1:]\n",
    "            \n",
    "            img_path = self.radiografias_path / file_name\n",
    "            if not img_path.exists():\n",
    "                img_path = self.radiografias_path / Path(file_name).name\n",
    "            \n",
    "            if img_path.exists():\n",
    "                samples.append({\n",
    "                    'image_id': img_id,\n",
    "                    'image_path': str(img_path),\n",
    "                    'annotations': anns_por_imagen[img_id]\n",
    "                })\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    def _parsear_segmentacion(self, segmentation):\n",
    "        poligonos = []\n",
    "        if not segmentation or not isinstance(segmentation, list):\n",
    "            return poligonos\n",
    "        \n",
    "        for seg_item in segmentation:\n",
    "            if isinstance(seg_item, list) and seg_item:\n",
    "                if isinstance(seg_item[0], (int, float)) and len(seg_item) >= 6:\n",
    "                    coords = np.array(seg_item).reshape(-1, 2)\n",
    "                    if coords.shape[0] >= 3:\n",
    "                        poligonos.append(coords.astype(np.int32))\n",
    "        return poligonos\n",
    "    \n",
    "    def _crear_mascara(self, annotations, orig_height, orig_width):\n",
    "        mask = np.zeros((orig_height, orig_width), dtype=np.uint8)\n",
    "        \n",
    "        for ann in annotations:\n",
    "            name = ann.get('name', '').strip()\n",
    "            \n",
    "            if name not in self.name_to_class:\n",
    "                continue\n",
    "            \n",
    "            class_id = self.name_to_class[name]\n",
    "            poligonos = self._parsear_segmentacion(ann.get('segmentation'))\n",
    "            \n",
    "            for poly in poligonos:\n",
    "                cv2.fillPoly(mask, [poly], class_id)\n",
    "            \n",
    "            if not poligonos and 'bbox' in ann:\n",
    "                bbox = ann['bbox']\n",
    "                x, y, w, h = [int(v) for v in bbox]\n",
    "                if x >= 0 and y >= 0 and w > 0 and h > 0:\n",
    "                    x2, y2 = min(x+w, orig_width), min(y+h, orig_height)\n",
    "                    mask[y:y2, x:x2] = class_id\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        image = Image.open(sample['image_path']).convert('RGB')\n",
    "        orig_width, orig_height = image.size\n",
    "        mask = self._crear_mascara(sample['annotations'], orig_height, orig_width)\n",
    "        \n",
    "        image = image.resize(self.target_size, Image.BILINEAR)\n",
    "        mask = cv2.resize(mask, self.target_size, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        image = self.transform(image)\n",
    "        mask = torch.from_numpy(mask).long()\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "print(\"âœ“ Dataset definido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08939e39-7276-466d-a1ea-35c159636ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        pred = F.softmax(pred, dim=1)\n",
    "        target_one_hot = F.one_hot(target, num_classes=pred.shape[1]).permute(0, 3, 1, 2).float()\n",
    "        \n",
    "        intersection = (pred * target_one_hot).sum(dim=(2, 3))\n",
    "        union = pred.sum(dim=(2, 3)) + target_one_hot.sum(dim=(2, 3))\n",
    "        \n",
    "        dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
    "        return 1.0 - dice.mean()\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, ce_weight=0.5, dice_weight=0.5):\n",
    "        super().__init__()\n",
    "        self.ce_weight = ce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.dice_loss = DiceLoss()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        ce = self.ce_loss(pred, target)\n",
    "        dice = self.dice_loss(pred, target)\n",
    "        return self.ce_weight * ce + self.dice_weight * dice\n",
    "\n",
    "def calcular_metricas_detalladas(pred, target, num_classes, class_names):\n",
    "    \"\"\"Calcula mÃ©tricas detalladas por clase\"\"\"\n",
    "    pred_classes = torch.argmax(pred, dim=1)\n",
    "    metricas = {}\n",
    "    \n",
    "    for c in range(num_classes):\n",
    "        pred_c = (pred_classes == c)\n",
    "        target_c = (target == c)\n",
    "        intersection = (pred_c & target_c).sum().float()\n",
    "        union = (pred_c | target_c).sum().float()\n",
    "        \n",
    "        if union > 0:\n",
    "            iou = (intersection / union).item()\n",
    "            dice = (2 * intersection / (pred_c.sum() + target_c.sum())).item()\n",
    "        else:\n",
    "            iou = 0.0\n",
    "            dice = 0.0\n",
    "        \n",
    "        class_name = class_names[c] if c < len(class_names) else f'class_{c}'\n",
    "        metricas[f'iou_{class_name}'] = iou\n",
    "        metricas[f'dice_{class_name}'] = dice\n",
    "    \n",
    "    ious_sin_bg = [metricas[f'iou_{class_names[c]}'] for c in range(1, num_classes)]\n",
    "    dices_sin_bg = [metricas[f'dice_{class_names[c]}'] for c in range(1, num_classes)]\n",
    "    \n",
    "    metricas['mean_iou'] = np.mean(ious_sin_bg) if ious_sin_bg else 0.0\n",
    "    metricas['mean_dice'] = np.mean(dices_sin_bg) if dices_sin_bg else 0.0\n",
    "    metricas['accuracy'] = (pred_classes == target).float().mean().item()\n",
    "    \n",
    "    return metricas\n",
    "\n",
    "print(\"âœ“ Loss functions y mÃ©tricas definidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e576350-622c-430f-a6b2-155461328841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device, num_classes, class_names):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_metrics = defaultdict(float)\n",
    "    \n",
    "    for images, masks in dataloader:\n",
    "        if images.size(0) == 1:\n",
    "            continue\n",
    "            \n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        metricas = calcular_metricas_detalladas(outputs, masks, num_classes, class_names)\n",
    "        for k, v in metricas.items():\n",
    "            total_metrics[k] += v\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_metrics = {k: v / len(dataloader) for k, v in total_metrics.items()}\n",
    "    return avg_loss, avg_metrics\n",
    "\n",
    "def validate(model, dataloader, criterion, device, num_classes, class_names):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_metrics = defaultdict(float)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            metricas = calcular_metricas_detalladas(outputs, masks, num_classes, class_names)\n",
    "            for k, v in metricas.items():\n",
    "                total_metrics[k] += v\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_metrics = {k: v / len(dataloader) for k, v in total_metrics.items()}\n",
    "    return avg_loss, avg_metrics\n",
    "\n",
    "print(\"âœ“ Funciones de entrenamiento definidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bfe3a0-bcc5-434b-a12d-2f52ef775dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, model_name, model, train_loader, val_loader, device, \n",
    "                 num_classes, class_names, lr=0.0001, max_epochs=50):\n",
    "        self.model_name = model_name\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes\n",
    "        self.class_names = class_names\n",
    "        self.max_epochs = max_epochs\n",
    "        \n",
    "        self.optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "        self.criterion = CombinedLoss(ce_weight=0.5, dice_weight=0.5)\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='max', factor=0.5, patience=7\n",
    "        )\n",
    "        \n",
    "        self.history = defaultdict(list)\n",
    "        self.best_iou = 0\n",
    "        self.best_dice = 0\n",
    "        self.best_epoch = 0\n",
    "        self.training_time = 0\n",
    "        self.best_metrics_per_class = {}\n",
    "    \n",
    "    def train(self):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ðŸš€ Entrenando: {self.model_name}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        patience_counter = 0\n",
    "        patience = 15\n",
    "        \n",
    "        for epoch in range(self.max_epochs):\n",
    "            print(f\"\\nðŸ“Š Epoca {epoch+1}/{self.max_epochs}\")\n",
    "            print(\"-\"*70)\n",
    "            \n",
    "            train_loss, train_metrics = train_epoch(\n",
    "                self.model, self.train_loader, self.criterion, \n",
    "                self.optimizer, self.device, self.num_classes, self.class_names\n",
    "            )\n",
    "            \n",
    "            val_loss, val_metrics = validate(\n",
    "                self.model, self.val_loader, self.criterion,\n",
    "                self.device, self.num_classes, self.class_names\n",
    "            )\n",
    "            \n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            for key in val_metrics:\n",
    "                self.history[f'train_{key}'].append(train_metrics[key])\n",
    "                self.history[f'val_{key}'].append(val_metrics[key])\n",
    "            \n",
    "            print(f\"Train | Loss: {train_loss:.4f} | IoU: {train_metrics['mean_iou']:.4f} | \"\n",
    "                  f\"Dice: {train_metrics['mean_dice']:.4f}\")\n",
    "            print(f\"Val   | Loss: {val_loss:.4f} | IoU: {val_metrics['mean_iou']:.4f} | \"\n",
    "                  f\"Dice: {val_metrics['mean_dice']:.4f}\")\n",
    "            \n",
    "            print(\"\\n  MÃ©tricas por clase (ValidaciÃ³n):\")\n",
    "            for c in range(1, self.num_classes):\n",
    "                class_name = self.class_names[c]\n",
    "                iou = val_metrics[f'iou_{class_name}']\n",
    "                dice = val_metrics[f'dice_{class_name}']\n",
    "                print(f\"    {class_name:>10}: IoU={iou:.4f} | Dice={dice:.4f}\")\n",
    "            \n",
    "            if val_metrics['mean_iou'] > self.best_iou:\n",
    "                self.best_iou = val_metrics['mean_iou']\n",
    "                self.best_dice = val_metrics['mean_dice']\n",
    "                self.best_epoch = epoch + 1\n",
    "                patience_counter = 0\n",
    "                \n",
    "                self.best_metrics_per_class = {\n",
    "                    class_name: {\n",
    "                        'iou': val_metrics[f'iou_{class_name}'],\n",
    "                        'dice': val_metrics[f'dice_{class_name}']\n",
    "                    }\n",
    "                    for class_name in self.class_names[1:]\n",
    "                }\n",
    "                \n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'best_iou': self.best_iou,\n",
    "                    'best_dice': self.best_dice,\n",
    "                    'best_metrics_per_class': self.best_metrics_per_class,\n",
    "                    'history': dict(self.history)\n",
    "                }, f'{self.model_name.lower().replace(\" \", \"_\").replace(\"+\", \"plus\").replace(\"-\", \"_\")}_best.pth')\n",
    "                print(f\"âœ“ ðŸ† Mejor modelo guardado! IoU: {self.best_iou:.4f} | Dice: {self.best_dice:.4f}\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            self.scheduler.step(val_metrics['mean_iou'])\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\nâ¹ï¸  Early stopping en epoca {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        self.training_time = time.time() - start_time\n",
    "        print(f\"\\nâ±ï¸  Tiempo: {self.training_time/60:.2f} min\")\n",
    "        print(f\"ðŸ† Mejor IoU: {self.best_iou:.4f} | Dice: {self.best_dice:.4f} (Epoca {self.best_epoch})\")\n",
    "        \n",
    "        return self.history, self.best_iou\n",
    "    \n",
    "    def get_results(self):\n",
    "        total_params = sum(p.numel() for p in self.model.parameters())\n",
    "        return {\n",
    "            'model_name': self.model_name,\n",
    "            'best_iou': self.best_iou,\n",
    "            'best_dice': self.best_dice,\n",
    "            'best_epoch': self.best_epoch,\n",
    "            'training_time': self.training_time,\n",
    "            'total_params': total_params,\n",
    "            'history': dict(self.history),\n",
    "            'best_metrics_per_class': self.best_metrics_per_class\n",
    "        }\n",
    "\n",
    "print(\"âœ“ Model Trainer definido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026702ab-5d36-46d5-96ec-87e50b48a900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizar_predicciones_modelo(model, dataset, device, model_name, class_names, num_samples=4, seed=1111):\n",
    "    \"\"\"Visualiza predicciones de un modelo especÃ­fico comparadas con ground truth\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    colors = {\n",
    "        0: [0, 0, 0],\n",
    "        1: [0, 255, 0],\n",
    "        2: [0, 0, 255]\n",
    "    }\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(18, num_samples * 4.5))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.choice(len(dataset), min(num_samples, len(dataset)), replace=False)\n",
    "    \n",
    "    mean = torch.tensor([0.399637, 0.400040, 0.392532]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.212403, 0.211738, 0.207753]).view(3, 1, 1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, idx in enumerate(indices):\n",
    "            image, mask = dataset[idx]\n",
    "            \n",
    "            image_input = image.unsqueeze(0).to(device)\n",
    "            pred = model(image_input).cpu().squeeze(0)\n",
    "            pred_classes = torch.argmax(pred, dim=0).numpy()\n",
    "            \n",
    "            image_denorm = image * std + mean\n",
    "            img_np = image_denorm.permute(1, 2, 0).numpy()\n",
    "            img_np = np.clip(img_np, 0, 1)\n",
    "            \n",
    "            mask_np = mask.numpy()\n",
    "            \n",
    "            pred_colored = np.zeros((*pred_classes.shape, 3), dtype=np.uint8)\n",
    "            mask_colored = np.zeros((*mask_np.shape, 3), dtype=np.uint8)\n",
    "            \n",
    "            for class_id, color in colors.items():\n",
    "                pred_colored[pred_classes == class_id] = color\n",
    "                mask_colored[mask_np == class_id] = color\n",
    "            \n",
    "            metricas = calcular_metricas_detalladas(\n",
    "                pred.unsqueeze(0), \n",
    "                mask.unsqueeze(0), \n",
    "                len(colors), \n",
    "                class_names\n",
    "            )\n",
    "            \n",
    "            axes[i, 0].imshow(img_np)\n",
    "            axes[i, 0].set_title('ðŸ–¼ï¸ Imagen Original', fontsize=12, fontweight='bold')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            axes[i, 1].imshow(mask_colored)\n",
    "            axes[i, 1].set_title('âœ“ Ground Truth', fontsize=12, fontweight='bold')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            axes[i, 2].imshow(pred_colored)\n",
    "            axes[i, 2].set_title(f'ðŸ¤– PredicciÃ³n\\nIoU: {metricas[\"mean_iou\"]:.3f} | Dice: {metricas[\"mean_dice\"]:.3f}', \n",
    "                                fontsize=12, fontweight='bold')\n",
    "            axes[i, 2].axis('off')\n",
    "            \n",
    "            axes[i, 3].imshow(img_np)\n",
    "            axes[i, 3].imshow(pred_colored / 255.0, alpha=0.6)\n",
    "            axes[i, 3].set_title('ðŸŽ¨ Overlay', fontsize=12, fontweight='bold')\n",
    "            axes[i, 3].axis('off')\n",
    "    \n",
    "    legend_elements = [\n",
    "        plt.Rectangle((0, 0), 1, 1, fc=np.array(colors[i])/255.0, \n",
    "                     edgecolor='black', linewidth=2,\n",
    "                     label=class_names[i]) \n",
    "        for i in range(1, len(class_names))\n",
    "    ]\n",
    "    fig.legend(handles=legend_elements, loc='upper center', ncol=len(class_names)-1, \n",
    "              fontsize=12, frameon=True, fancybox=True, shadow=True)\n",
    "    \n",
    "    plt.suptitle(f'ðŸ” Predicciones de {model_name}', fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "    \n",
    "    filename = f'pred_{model_name.lower().replace(\" \", \"_\").replace(\"+\", \"plus\").replace(\"-\", \"_\")}_seed{seed}.png'\n",
    "    plt.savefig(filename, dpi=200, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    print(f\"   ðŸ“¸ Predicciones guardadas en: {filename}\")\n",
    "\n",
    "print(\"âœ“ Funciones de visualizaciÃ³n definidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52083d03-1513-478f-9d12-99d7d0a5b7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizar_comparacion_con_clases(resultados, class_names, output_file='comparacion_multimodal_actualizada.png'):\n",
    "    \"\"\"VisualizaciÃ³n completa con todos los grÃ¡ficos\"\"\"\n",
    "    fig = plt.figure(figsize=(24, 18))\n",
    "    gs = fig.add_gridspec(5, 4, hspace=0.4, wspace=0.35)\n",
    "    \n",
    "    # 1. IoU promedio\n",
    "    ax1 = fig.add_subplot(gs[0, :2])\n",
    "    for result in resultados:\n",
    "        ax1.plot(result['history']['val_mean_iou'], label=result['model_name'], linewidth=2.5, alpha=0.8)\n",
    "    ax1.set_xlabel('Epoca', fontsize=13, fontweight='bold')\n",
    "    ax1.set_ylabel('Validation IoU (Promedio)', fontsize=13, fontweight='bold')\n",
    "    ax1.set_title('ðŸ“ˆ ComparaciÃ³n IoU Promedio', fontsize=15, fontweight='bold')\n",
    "    ax1.legend(fontsize=10, loc='best')\n",
    "    ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax1.set_ylim([0, 1])\n",
    "    \n",
    "    # 2. Dice promedio\n",
    "    ax2 = fig.add_subplot(gs[0, 2:])\n",
    "    for result in resultados:\n",
    "        ax2.plot(result['history']['val_mean_dice'], label=result['model_name'], linewidth=2.5, alpha=0.8)\n",
    "    ax2.set_xlabel('Epoca', fontsize=13, fontweight='bold')\n",
    "    ax2.set_ylabel('Validation Dice (Promedio)', fontsize=13, fontweight='bold')\n",
    "    ax2.set_title('ðŸ“ˆ ComparaciÃ³n Dice Score Promedio', fontsize=15, fontweight='bold')\n",
    "    ax2.legend(fontsize=10, loc='best')\n",
    "    ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax2.set_ylim([0, 1])\n",
    "    \n",
    "    # 3-4. IoU por clase\n",
    "    vertebra_classes = class_names[1:]\n",
    "    colors_per_model = plt.cm.tab10(np.linspace(0, 1, len(resultados)))\n",
    "    \n",
    "    for idx, vertebra in enumerate(vertebra_classes):\n",
    "        ax = fig.add_subplot(gs[1, idx])\n",
    "        for i, result in enumerate(resultados):\n",
    "            key = f'val_iou_{vertebra}'\n",
    "            if key in result['history']:\n",
    "                ax.plot(result['history'][key], label=result['model_name'], \n",
    "                       linewidth=2.5, alpha=0.8, color=colors_per_model[i])\n",
    "        ax.set_xlabel('Epoca', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel(f'IoU {vertebra}', fontsize=12, fontweight='bold')\n",
    "        ax.set_title(f'ðŸ“Š IoU - VÃ©rtebra {vertebra}', fontsize=13, fontweight='bold')\n",
    "        ax.legend(fontsize=8, loc='best')\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax.set_ylim([0, 1])\n",
    "    \n",
    "    # Loss\n",
    "    ax_loss = fig.add_subplot(gs[1, 2])\n",
    "    for result in resultados:\n",
    "        ax_loss.plot(result['history']['val_loss'], label=result['model_name'], linewidth=2.5, alpha=0.8)\n",
    "    ax_loss.set_xlabel('Epoca', fontsize=12, fontweight='bold')\n",
    "    ax_loss.set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
    "    ax_loss.set_title('ðŸ“‰ Validation Loss', fontsize=13, fontweight='bold')\n",
    "    ax_loss.legend(fontsize=8, loc='best')\n",
    "    ax_loss.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Accuracy\n",
    "    ax_acc = fig.add_subplot(gs[1, 3])\n",
    "    for result in resultados:\n",
    "        ax_acc.plot(result['history']['val_accuracy'], label=result['model_name'], linewidth=2.5, alpha=0.8)\n",
    "    ax_acc.set_xlabel('Epoca', fontsize=12, fontweight='bold')\n",
    "    ax_acc.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "    ax_acc.set_title('ðŸŽ¯ Validation Accuracy', fontsize=13, fontweight='bold')\n",
    "    ax_acc.legend(fontsize=8, loc='best')\n",
    "    ax_acc.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax_acc.set_ylim([0, 1])\n",
    "    \n",
    "    # Ranking por IoU\n",
    "    ax7 = fig.add_subplot(gs[2, 0])\n",
    "    nombres = [r['model_name'] for r in resultados]\n",
    "    ious = [r['best_iou'] for r in resultados]\n",
    "    colors = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(nombres)))\n",
    "    bars = ax7.barh(nombres, ious, color=colors, edgecolor='black', linewidth=1.5)\n",
    "    ax7.set_xlabel('Best IoU (Promedio)', fontsize=11, fontweight='bold')\n",
    "    ax7.set_title('ðŸ† Ranking IoU General', fontsize=12, fontweight='bold')\n",
    "    ax7.grid(True, alpha=0.3, axis='x')\n",
    "    ax7.set_xlim([0, 1])\n",
    "    for bar, iou in zip(bars, ious):\n",
    "        ax7.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                f'{iou:.4f}', va='center', ha='left', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # IoU por clase (barras)\n",
    "    for idx, vertebra in enumerate(vertebra_classes):\n",
    "        ax = fig.add_subplot(gs[2, idx+1])\n",
    "        ious_class = [r['best_metrics_per_class'][vertebra]['iou'] for r in resultados]\n",
    "        bars = ax.barh(nombres, ious_class, color=colors, edgecolor='black', linewidth=1.5)\n",
    "        ax.set_xlabel(f'IoU {vertebra}', fontsize=11, fontweight='bold')\n",
    "        ax.set_title(f'ðŸ† IoU - {vertebra}', fontsize=12, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        ax.set_xlim([0, 1])\n",
    "        for bar, iou in zip(bars, ious_class):\n",
    "            ax.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                   f'{iou:.3f}', va='center', ha='left', fontsize=8, fontweight='bold')\n",
    "    \n",
    "    # Heatmap IoU\n",
    "    ax11 = fig.add_subplot(gs[3, :2])\n",
    "    data_matrix = []\n",
    "    for result in resultados:\n",
    "        row = [result['best_metrics_per_class'][v]['iou'] for v in vertebra_classes]\n",
    "        data_matrix.append(row)\n",
    "    \n",
    "    im = ax11.imshow(data_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
    "    ax11.set_xticks(range(len(vertebra_classes)))\n",
    "    ax11.set_xticklabels(vertebra_classes, fontsize=11, fontweight='bold')\n",
    "    ax11.set_yticks(range(len(nombres)))\n",
    "    ax11.set_yticklabels(nombres, fontsize=11)\n",
    "    ax11.set_title('ðŸ”¥ Heatmap IoU por Modelo y Clase', fontsize=13, fontweight='bold')\n",
    "    \n",
    "    for i in range(len(nombres)):\n",
    "        for j in range(len(vertebra_classes)):\n",
    "            text = ax11.text(j, i, f'{data_matrix[i][j]:.3f}',\n",
    "                           ha=\"center\", va=\"center\", color=\"black\", fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.colorbar(im, ax=ax11, label='IoU Score')\n",
    "    \n",
    "    # Heatmap Dice\n",
    "    ax12 = fig.add_subplot(gs[3, 2:])\n",
    "    data_matrix_dice = []\n",
    "    for result in resultados:\n",
    "        row = [result['best_metrics_per_class'][v]['dice'] for v in vertebra_classes]\n",
    "        data_matrix_dice.append(row)\n",
    "    \n",
    "    im2 = ax12.imshow(data_matrix_dice, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
    "    ax12.set_xticks(range(len(vertebra_classes)))\n",
    "    ax12.set_xticklabels(vertebra_classes, fontsize=11, fontweight='bold')\n",
    "    ax12.set_yticks(range(len(nombres)))\n",
    "    ax12.set_yticklabels(nombres, fontsize=11)\n",
    "    ax12.set_title('ðŸ”¥ Heatmap Dice por Modelo y Clase', fontsize=13, fontweight='bold')\n",
    "    \n",
    "    for i in range(len(nombres)):\n",
    "        for j in range(len(vertebra_classes)):\n",
    "            text = ax12.text(j, i, f'{data_matrix_dice[i][j]:.3f}',\n",
    "                           ha=\"center\", va=\"center\", color=\"black\", fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.colorbar(im2, ax=ax12, label='Dice Score')\n",
    "    \n",
    "    # ComparaciÃ³n de TamaÃ±o\n",
    "    ax13 = fig.add_subplot(gs[4, :2])\n",
    "    params = [r['total_params'] / 1e6 for r in resultados]\n",
    "    colors_size = plt.cm.viridis(np.linspace(0.2, 0.9, len(nombres)))\n",
    "    bars = ax13.barh(nombres, params, color=colors_size, edgecolor='black', linewidth=1.5)\n",
    "    ax13.set_xlabel('ParÃ¡metros (Millones)', fontsize=11, fontweight='bold')\n",
    "    ax13.set_title('ðŸ“Š TamaÃ±o de Modelos (ParÃ¡metros)', fontsize=12, fontweight='bold')\n",
    "    ax13.grid(True, alpha=0.3, axis='x')\n",
    "    for bar, param, result in zip(bars, params, resultados):\n",
    "        size_mb = (result['total_params'] * 4) / (1024 * 1024)\n",
    "        ax13.text(bar.get_width() + max(params)*0.01, bar.get_y() + bar.get_height()/2, \n",
    "                 f'{param:.2f}M ({size_mb:.1f}MB)', \n",
    "                 va='center', ha='left', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Eficiencia: IoU vs TamaÃ±o\n",
    "    ax14 = fig.add_subplot(gs[4, 2:])\n",
    "    params_plot = [r['total_params'] / 1e6 for r in resultados]\n",
    "    ious_plot = [r['best_iou'] for r in resultados]\n",
    "    scatter = ax14.scatter(params_plot, ious_plot, c=range(len(resultados)), \n",
    "                          s=300, cmap='tab10', edgecolor='black', linewidth=2, alpha=0.8)\n",
    "    \n",
    "    for i, (p, iou, nombre) in enumerate(zip(params_plot, ious_plot, nombres)):\n",
    "        ax14.annotate(nombre, (p, iou), \n",
    "                     xytext=(10, 5), textcoords='offset points',\n",
    "                     fontsize=9, fontweight='bold',\n",
    "                     bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.3))\n",
    "    \n",
    "    ax14.set_xlabel('ParÃ¡metros (Millones)', fontsize=11, fontweight='bold')\n",
    "    ax14.set_ylabel('Best IoU', fontsize=11, fontweight='bold')\n",
    "    ax14.set_title('âš–ï¸ Eficiencia: IoU vs TamaÃ±o del Modelo', fontsize=12, fontweight='bold')\n",
    "    ax14.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax14.set_ylim([min(ious_plot)*0.95, max(ious_plot)*1.05])\n",
    "    \n",
    "    plt.suptitle('ðŸ”¬ COMPARACIÃ“N COMPLETA: MODELOS CLÃSICOS + NUEVOS MODELOS LIGEROS', \n",
    "                 fontsize=18, fontweight='bold', y=0.995)\n",
    "    \n",
    "    plt.savefig(output_file, dpi=200, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    print(f\"\\nðŸ“Š ComparaciÃ³n detallada guardada en: {output_file}\")\n",
    "\n",
    "print(\"âœ“ FunciÃ³n de comparaciÃ³n completa definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb4ecd-b605-44fa-affe-7d15cfbe849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # CONFIGURACIÃ“N\n",
    "    SEED = 1111\n",
    "    BASE_PATH = r\"C:\\Users\\User\\Documents\\Proyectofinal\"\n",
    "    BATCH_SIZE = 8\n",
    "    MAX_EPOCHS = 100\n",
    "    LEARNING_RATE = 0.0001\n",
    "    IMAGE_SIZE = 256\n",
    "    NUM_CLASSES = 3\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ”¬ ANÃLISIS MULTI-MODELO: CLÃSICOS + NUEVOS MODELOS LIGEROS\")\n",
    "    print(\"   Modelos ClÃ¡sicos: DeepLabV3+, LinkNet, PSPNet, U-Net++\")\n",
    "    print(\"   Nuevos Modelos: MobileNetV3-UNet, MobileViT-XSmall\")\n",
    "    print(f\"   SEED: {SEED}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    set_seed(SEED)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nðŸ’» Dispositivo: {device}\")\n",
    "    if device.type == 'cuda':\n",
    "        print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # CARGAR DATASET\n",
    "    print(\"\\nðŸ“¦ Cargando dataset...\")\n",
    "    full_dataset = VertebrasDataset(BASE_PATH, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "    class_names = full_dataset.class_names\n",
    "    \n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    \n",
    "    generator = torch.Generator().manual_seed(SEED)\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        full_dataset, [train_size, val_size], generator=generator\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Total: {len(full_dataset)} | Train: {len(train_dataset)} | Val: {len(val_dataset)}\")\n",
    "    print(f\"âœ“ Clases: {class_names}\")\n",
    "    \n",
    "    def seed_worker(worker_id):\n",
    "        worker_seed = SEED + worker_id\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "    \n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(SEED)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "        num_workers=0, worker_init_fn=seed_worker, generator=g,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "        num_workers=0, worker_init_fn=seed_worker,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    # MODELOS: CLÃSICOS + NUEVOS\n",
    "    modelos = {\n",
    "        # Modelos ClÃ¡sicos\n",
    "        'DeepLabV3+': DeepLabV3Plus(in_channels=3, num_classes=NUM_CLASSES),\n",
    "        'LinkNet': LinkNet(in_channels=3, num_classes=NUM_CLASSES),\n",
    "        'PSPNet': PSPNet(in_channels=3, num_classes=NUM_CLASSES),\n",
    "        'U-Net++': UNetPlusPlus(in_channels=3, num_classes=NUM_CLASSES),\n",
    "        \n",
    "        # Nuevos Modelos Ligeros\n",
    "        'MobileNetV3-UNet': MobileNetV3UNet(in_channels=3, num_classes=NUM_CLASSES),\n",
    "        'MobileViT-XSmall': MobileViTXSmall(in_channels=3, num_classes=NUM_CLASSES)\n",
    "    }\n",
    "    \n",
    "    # Mostrar informaciÃ³n de modelos\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ðŸ“Š INFORMACIÃ“N DE MODELOS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    for nombre, modelo in modelos.items():\n",
    "        params = sum(p.numel() for p in modelo.parameters())\n",
    "        size_mb = (params * 4) / (1024 * 1024)\n",
    "        print(f\"  {nombre:20s}: {params/1e6:>6.2f}M params | {size_mb:>6.1f} MB\")\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ðŸ INICIANDO ENTRENAMIENTO DE {len(modelos)} MODELOS\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # ENTRENAR TODOS LOS MODELOS\n",
    "    for idx, (nombre, modelo) in enumerate(modelos.items(), 1):\n",
    "        print(f\"\\n{'â–¶'*3} Modelo {idx}/{len(modelos)}: {nombre} {'â—€'*3}\")\n",
    "        \n",
    "        set_seed(SEED)\n",
    "        \n",
    "        trainer = ModelTrainer(\n",
    "            model_name=nombre,\n",
    "            model=modelo,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            device=device,\n",
    "            num_classes=NUM_CLASSES,\n",
    "            class_names=class_names,\n",
    "            lr=LEARNING_RATE,\n",
    "            max_epochs=MAX_EPOCHS\n",
    "        )\n",
    "        \n",
    "        trainer.train()\n",
    "        resultados.append(trainer.get_results())\n",
    "        \n",
    "        # Visualizar predicciones\n",
    "        print(f\"\\nðŸ“¸ Generando visualizaciones para {nombre}...\")\n",
    "        visualizar_predicciones_modelo(\n",
    "            modelo, val_dataset, device, nombre, class_names, \n",
    "            num_samples=4, seed=SEED\n",
    "        )\n",
    "        \n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "    \n",
    "    # ORDENAR POR IoU\n",
    "    resultados = sorted(resultados, key=lambda x: x['best_iou'], reverse=True)\n",
    "    \n",
    "    # VISUALIZACIÃ“N COMPARATIVA\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ðŸ“Š GENERANDO VISUALIZACIONES COMPARATIVAS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    visualizar_comparacion_con_clases(resultados, class_names)\n",
    "    \n",
    "    # RESUMEN DETALLADO\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ðŸ† RESUMEN DETALLADO DE RESULTADOS\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    for i, r in enumerate(resultados, 1):\n",
    "        emoji = \"ðŸ¥‡\" if i == 1 else \"ðŸ¥ˆ\" if i == 2 else \"ðŸ¥‰\" if i == 3 else \"  \"\n",
    "        params_m = r['total_params'] / 1e6\n",
    "        size_mb = (r['total_params'] * 4) / (1024 * 1024)\n",
    "        \n",
    "        print(f\"{emoji} {i}. {r['model_name']}\")\n",
    "        print(f\"   IoU Promedio: {r['best_iou']:.4f} | Dice Promedio: {r['best_dice']:.4f}\")\n",
    "        print(f\"   ParÃ¡metros: {params_m:.2f}M | TamaÃ±o: {size_mb:.2f} MB\")\n",
    "        print(f\"   MÃ©tricas por clase:\")\n",
    "        for vertebra in class_names[1:]:\n",
    "            iou = r['best_metrics_per_class'][vertebra]['iou']\n",
    "            dice = r['best_metrics_per_class'][vertebra]['dice']\n",
    "            print(f\"     {vertebra:>10}: IoU={iou:.4f} | Dice={dice:.4f}\")\n",
    "        print(f\"   Epoca: {r['best_epoch']} | Tiempo: {r['training_time']/60:.1f} min\\n\")\n",
    "    \n",
    "    # ANÃLISIS DE EFICIENCIA\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"âš¡ ANÃLISIS DE EFICIENCIA\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    print(\"Modelos Ligeros (< 5M params):\")\n",
    "    for r in resultados:\n",
    "        if r['total_params'] < 5e6:\n",
    "            params_m = r['total_params'] / 1e6\n",
    "            eficiencia = r['best_iou'] / params_m * 100\n",
    "            print(f\"  {r['model_name']:20s}: IoU={r['best_iou']:.4f} | \"\n",
    "                  f\"Params={params_m:.2f}M | Eficiencia={eficiencia:.2f}\")\n",
    "    \n",
    "    print(\"\\nModelos Pesados (>= 5M params):\")\n",
    "    for r in resultados:\n",
    "        if r['total_params'] >= 5e6:\n",
    "            params_m = r['total_params'] / 1e6\n",
    "            eficiencia = r['best_iou'] / params_m * 100\n",
    "            print(f\"  {r['model_name']:20s}: IoU={r['best_iou']:.4f} | \"\n",
    "                  f\"Params={params_m:.2f}M | Eficiencia={eficiencia:.2f}\")\n",
    "    \n",
    "    # COMPARACIÃ“N NUEVOS vs CLÃSICOS\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ðŸ” COMPARACIÃ“N: NUEVOS MODELOS vs MEJOR MODELO CLÃSICO\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    modelos_clasicos = [r for r in resultados if r['model_name'] in ['DeepLabV3+', 'LinkNet', 'PSPNet', 'U-Net++']]\n",
    "    modelos_nuevos = [r for r in resultados if r['model_name'] in ['MobileNetV3-UNet', 'MobileViT-XSmall']]\n",
    "    \n",
    "    if modelos_clasicos and modelos_nuevos:\n",
    "        mejor_clasico = max(modelos_clasicos, key=lambda x: x['best_iou'])\n",
    "        \n",
    "        print(f\"Mejor ClÃ¡sico: {mejor_clasico['model_name']}\")\n",
    "        print(f\"  IoU: {mejor_clasico['best_iou']:.4f}\")\n",
    "        print(f\"  Params: {mejor_clasico['total_params']/1e6:.2f}M\")\n",
    "        print(f\"  Tiempo: {mejor_clasico['training_time']/60:.1f} min\\n\")\n",
    "        \n",
    "        for nuevo in modelos_nuevos:\n",
    "            print(f\"{nuevo['model_name']}:\")\n",
    "            print(f\"  IoU: {nuevo['best_iou']:.4f}\")\n",
    "            print(f\"  Params: {nuevo['total_params']/1e6:.2f}M\")\n",
    "            print(f\"  Tiempo: {nuevo['training_time']/60:.1f} min\")\n",
    "            \n",
    "            reduccion_params = (1 - nuevo['total_params'] / mejor_clasico['total_params']) * 100\n",
    "            diff_iou = nuevo['best_iou'] - mejor_clasico['best_iou']\n",
    "            \n",
    "            print(f\"  ReducciÃ³n de ParÃ¡metros: {reduccion_params:.1f}%\")\n",
    "            print(f\"  Diferencia de IoU: {diff_iou:+.4f}\")\n",
    "            \n",
    "            if diff_iou >= -0.02:\n",
    "                print(f\"  âœ… Logra {reduccion_params:.1f}% menos parÃ¡metros con rendimiento similar!\")\n",
    "            elif diff_iou > 0:\n",
    "                print(f\"  ðŸŽ‰ SUPERA al mejor clÃ¡sico con {reduccion_params:.1f}% menos parÃ¡metros!\")\n",
    "            print()\n",
    "    \n",
    "    # GUARDAR RESUMEN\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f'resultados_multimodal_seed{SEED}_{timestamp}.txt'\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"ANÃLISIS COMPLETO: MODELOS CLÃSICOS + NUEVOS MODELOS LIGEROS\\n\")\n",
    "        f.write(f\"SEED: {SEED}\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Dataset: {len(full_dataset)} imÃ¡genes\\n\")\n",
    "        f.write(f\"Clases: {', '.join(class_names)}\\n\\n\")\n",
    "        \n",
    "        f.write(\"MODELOS EVALUADOS:\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\")\n",
    "        f.write(\"ClÃ¡sicos: DeepLabV3+, LinkNet, PSPNet, U-Net++\\n\")\n",
    "        f.write(\"Nuevos: MobileNetV3-UNet, MobileViT-XSmall\\n\\n\")\n",
    "        \n",
    "        f.write(\"RESULTADOS POR MODELO:\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        for i, r in enumerate(resultados, 1):\n",
    "            params_m = r['total_params'] / 1e6\n",
    "            size_mb = (r['total_params'] * 4) / (1024 * 1024)\n",
    "            \n",
    "            f.write(f\"{i}. {r['model_name']}:\\n\")\n",
    "            f.write(f\"   IoU Promedio: {r['best_iou']:.4f}\\n\")\n",
    "            f.write(f\"   Dice Promedio: {r['best_dice']:.4f}\\n\")\n",
    "            f.write(f\"   ParÃ¡metros: {params_m:.2f}M ({r['total_params']:,})\\n\")\n",
    "            f.write(f\"   TamaÃ±o: {size_mb:.2f} MB\\n\")\n",
    "            f.write(f\"   Mejor Epoca: {r['best_epoch']}\\n\")\n",
    "            f.write(f\"   Tiempo: {r['training_time']/60:.2f} min\\n\\n\")\n",
    "            f.write(f\"   MÃ©tricas por clase:\\n\")\n",
    "            for vertebra in class_names[1:]:\n",
    "                iou = r['best_metrics_per_class'][vertebra]['iou']\n",
    "                dice = r['best_metrics_per_class'][vertebra]['dice']\n",
    "                f.write(f\"     {vertebra}: IoU={iou:.4f}, Dice={dice:.4f}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        f.write(f\"{'='*80}\\n\")\n",
    "        f.write(f\"MEJOR MODELO GENERAL: {resultados[0]['model_name']}\\n\")\n",
    "        f.write(f\"IoU: {resultados[0]['best_iou']:.4f}\\n\")\n",
    "        \n",
    "        if modelos_clasicos and modelos_nuevos:\n",
    "            f.write(f\"\\n{'='*80}\\n\")\n",
    "            f.write(\"COMPARACIÃ“N: NUEVOS MODELOS vs CLÃSICOS\\n\")\n",
    "            f.write(f\"{'='*80}\\n\\n\")\n",
    "            f.write(f\"Mejor ClÃ¡sico: {mejor_clasico['model_name']} (IoU: {mejor_clasico['best_iou']:.4f})\\n\\n\")\n",
    "            \n",
    "            for nuevo in modelos_nuevos:\n",
    "                reduccion_params = (1 - nuevo['total_params'] / mejor_clasico['total_params']) * 100\n",
    "                diff_iou = nuevo['best_iou'] - mejor_clasico['best_iou']\n",
    "                f.write(f\"{nuevo['model_name']}: IoU={nuevo['best_iou']:.4f}\\n\")\n",
    "                f.write(f\"  ReducciÃ³n de ParÃ¡metros: {reduccion_params:.1f}%\\n\")\n",
    "                f.write(f\"  Diferencia de IoU: {diff_iou:+.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(f\"\\n{'='*80}\\n\")\n",
    "        f.write(\"TABLA COMPARATIVA DE EFICIENCIA\\n\")\n",
    "        f.write(f\"{'='*80}\\n\\n\")\n",
    "        f.write(f\"{'Modelo':<20} {'Params':<12} {'TamaÃ±o':<12} {'IoU':<10} {'Efic.':<10}\\n\")\n",
    "        f.write(f\"{'-'*80}\\n\")\n",
    "        \n",
    "        for r in resultados:\n",
    "            params_m = r['total_params'] / 1e6\n",
    "            size_mb = (r['total_params'] * 4) / (1024 * 1024)\n",
    "            eficiencia = r['best_iou'] / params_m * 100\n",
    "            \n",
    "            f.write(f\"{r['model_name']:<20} {params_m:>6.2f}M      {size_mb:>6.1f} MB   \"\n",
    "                   f\"{r['best_iou']:<10.4f} {eficiencia:>8.2f}\\n\")\n",
    "    \n",
    "    print(f\"\\nðŸ“„ Resumen guardado en: {filename}\")\n",
    "    \n",
    "    # TABLA FINAL EN CONSOLA\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ðŸ“Š TABLA COMPARATIVA FINAL\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"{'Modelo':<20} {'Params':<12} {'TamaÃ±o':<12} {'IoU':<10} {'Efic.':<10}\")\n",
    "    print(f\"{'-'*80}\")\n",
    "    \n",
    "    for r in resultados:\n",
    "        params_m = r['total_params'] / 1e6\n",
    "        size_mb = (r['total_params'] * 4) / (1024 * 1024)\n",
    "        eficiencia = r['best_iou'] / params_m * 100\n",
    "        \n",
    "        print(f\"{r['model_name']:<20} {params_m:>6.2f}M      {size_mb:>6.1f} MB   \"\n",
    "              f\"{r['best_iou']:<10.4f} {eficiencia:>8.2f}\")\n",
    "    \n",
    "    print(f\"\\nâœ… ANÃLISIS COMPLETADO\")\n",
    "    print(f\"\\nðŸ“‹ ARCHIVOS GENERADOS:\")\n",
    "    print(f\"   âœ“ Visualizaciones por modelo: pred_*_seed{SEED}.png\")\n",
    "    print(f\"   âœ“ ComparaciÃ³n completa: comparacion_multimodal_actualizada.png\")\n",
    "    print(f\"   âœ“ Resumen detallado: {filename}\")\n",
    "    print(f\"   âœ“ Checkpoints: *_best.pth\")\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "print(\"âœ“ FunciÃ³n principal definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e066b6b4-8ca7-477a-a598-d63af677111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        resultados = main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nâš ï¸  Proceso interrumpido\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\nâŒ Error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
