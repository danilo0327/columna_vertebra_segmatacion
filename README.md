# SegmentaciÃ³n de Columna Vertebral y VÃ©rtebra T1

AplicaciÃ³n web para segmentaciÃ³n automÃ¡tica de columna vertebral (V) y vÃ©rtebra T1 en radiografÃ­as usando modelos de Deep Learning (DeepLabV3+, U-Net++, DeepLabV3++ con Decoder Denso).

## ğŸ¯ CaracterÃ­sticas

- **MÃºltiples modelos disponibles:**
  - DeepLabV3++ (Decoder Denso) - Modelo hÃ­brido con decoder denso
  - U-Net++ v2 - Arquitectura U-Net++ optimizada
  - DeepLabV3+ ResNet50 - Modelo estÃ¡ndar de torchvision

- **SegmentaciÃ³n de mÃºltiples clases:**
  - F (Fondo/Background)
  - V (Columna vertebral) - Visualizada en verde
  - T1 (VÃ©rtebra T1) - Visualizada en rojo

- **MÃ©tricas de evaluaciÃ³n:**
  - IoU (Intersection over Union) por clase
  - Dice Score por clase
  - Confianza promedio
  - Porcentaje de cobertura por clase

- **Interfaz web intuitiva:**
  - Carga de imÃ¡genes (PNG, JPG, DICOM)
  - VisualizaciÃ³n de resultados con superposiciÃ³n
  - SelecciÃ³n de modelo desde la interfaz
  - BotÃ³n para limpiar y cargar nueva imagen

## ğŸ§  Arquitectura del Modelo DeepLabV3+ ResNet50

El modelo principal utilizado es **DeepLabV3+ con backbone ResNet50**, una arquitectura de segmentaciÃ³n semÃ¡ntica de Ãºltima generaciÃ³n que combina un encoder profundo con un decoder refinado.

### Estructura de la Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ENCODER                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚ Input Image  â”‚ â†’ ResNet-50 Backbone                        â”‚
â”‚  â”‚ (512Ã—256Ã—3)  â”‚                                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚         â”‚                                                     â”‚
â”‚         â”œâ”€â†’ L_e: High-level features (conv4_block6_2_relu)   â”‚
â”‚         â”‚   â””â”€â†’ Atrous Spatial Pyramid Pooling (ASPP)       â”‚
â”‚         â”‚       â”œâ”€ 1Ã—1 Convolution                           â”‚
â”‚         â”‚       â”œâ”€ 3Ã—3 Convolution (rate=6)                  â”‚
â”‚         â”‚       â”œâ”€ 3Ã—3 Convolution (rate=12)                 â”‚
â”‚         â”‚       â”œâ”€ 3Ã—3 Convolution (rate=18)                  â”‚
â”‚         â”‚       â”œâ”€ Image Pooling                              â”‚
â”‚         â”‚       â””â”€ Concatenation â†’ 1Ã—1 Conv (ASPP Output)    â”‚
â”‚         â”‚                                                      â”‚
â”‚         â””â”€â†’ L_d: Low-level features (conv2_block3_2_relu)     â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DECODER                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚ ASPP Output      â”‚ â†’ Upsample by 4                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚         â”‚                                                     â”‚
â”‚         â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚ L_d Features     â”‚ â†’ 1Ã—1 Conv                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚         â”‚                                                     â”‚
â”‚         â””â”€â†’ Concatenation                                    â”‚
â”‚             â””â”€â†’ 3Ã—3 Convolution                              â”‚
â”‚                 â””â”€â†’ Upsample by 4                            â”‚
â”‚                     â””â”€â†’ Segmentation Mask (512Ã—256Ã—3)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes Principales

#### 1. **Encoder: ResNet-50 Backbone**
- **FunciÃ³n:** ExtracciÃ³n de caracterÃ­sticas multiescala
- **Salidas:**
  - **L_e (High-level):** CaracterÃ­sticas de alto nivel desde `conv4_block6_2_relu`
  - **L_d (Low-level):** CaracterÃ­sticas de bajo nivel desde `conv2_block3_2_relu`

#### 2. **Atrous Spatial Pyramid Pooling (ASPP)**
- **PropÃ³sito:** Capturar contexto a mÃºltiples escalas usando convoluciones atrous (dilated)
- **Componentes:**
  - 1Ã—1 ConvoluciÃ³n estÃ¡ndar
  - 3Ã—3 Convoluciones atrous con tasas 6, 12 y 18
  - Image Pooling (Adaptive Average Pooling)
  - ConcatenaciÃ³n y proyecciÃ³n final con 1Ã—1 convoluciÃ³n

#### 3. **Decoder**
- **FunciÃ³n:** Refinamiento de la segmentaciÃ³n usando caracterÃ­sticas de bajo nivel
- **Proceso:**
  1. Upsampling del output de ASPP (Ã—4)
  2. Procesamiento de caracterÃ­sticas de bajo nivel (L_d) con 1Ã—1 convoluciÃ³n
  3. ConcatenaciÃ³n de caracterÃ­sticas de alto y bajo nivel
  4. Refinamiento con 3Ã—3 convoluciÃ³n
  5. Upsampling final (Ã—4) para obtener la mÃ¡scara de segmentaciÃ³n

### Ventajas de esta Arquitectura

- **Contexto multiescala:** ASPP captura informaciÃ³n a diferentes escalas espaciales
- **Refinamiento preciso:** El decoder combina caracterÃ­sticas de alto y bajo nivel para bordes mÃ¡s precisos
- **Eficiencia:** ResNet-50 proporciona un buen balance entre precisiÃ³n y velocidad

## ğŸ“ ConfiguraciÃ³n del Entrenamiento

El modelo DeepLabV3+ ResNet50 fue entrenado con la siguiente configuraciÃ³n:

### Dataset

- **Total de imÃ¡genes:** 174 radiografÃ­as vÃ¡lidas
- **Anotaciones:** 499 anotaciones en formato COCO
- **Split:**
  - **Train:** 70% (121 imÃ¡genes)
  - **Validation:** 15% (26 imÃ¡genes)
  - **Test:** 15% (27 imÃ¡genes)
- **TamaÃ±o de imagen:** 512Ã—256 pÃ­xeles
- **Clases:** 3 clases (F=Fondo, V=Columna, T1=VÃ©rtebra T1)

### Preprocesamiento

- **Resize:** Todas las imÃ¡genes se redimensionan a 512Ã—256
- **NormalizaciÃ³n:** Valores de pÃ­xel normalizados a [0, 1]
- **Data Augmentation:**
  - Random horizontal flip (50% probabilidad)
  - InterpolaciÃ³n: `INTER_AREA` para imÃ¡genes, `INTER_NEAREST` para mÃ¡scaras

### HiperparÃ¡metros

| ParÃ¡metro | Valor |
|-----------|-------|
| **Batch Size** | 4 |
| **Epochs** | 50 |
| **Learning Rate** | 3Ã—10â»â´ (0.0003) |
| **Optimizer** | AdamW |
| **Weight Decay** | 1Ã—10â»â´ |
| **Scheduler** | CosineAnnealingLR (T_max=50) |
| **Loss Function** | Combined Loss (CE + Dice) |
|   - CE Weight | 0.6 |
|   - Dice Weight | 0.4 |
| **Class Weights** | [0.05, 1.0, 3.0] (F, V, T1) |

### FunciÃ³n de PÃ©rdida

Se utiliza una **pÃ©rdida combinada** que combina Cross-Entropy y Dice Loss:

```python
Loss = 0.6 Ã— CrossEntropy + 0.4 Ã— DiceLoss
```

- **Cross-Entropy:** Penaliza errores de clasificaciÃ³n
- **Dice Loss:** Enfocado en la superposiciÃ³n de regiones (Ãºtil para clases desbalanceadas)
- **Class Weights:** Pesos ajustados para manejar el desbalance (F >> V > T1)

### MÃ©tricas de EvaluaciÃ³n

- **IoU (Intersection over Union)** por clase
- **mIoU (mean IoU)** excluyendo fondo
- **Modelo guardado:** Se guarda el modelo con mejor IoU de T1 en validaciÃ³n

### Resultados del Entrenamiento

El modelo alcanzÃ³ los siguientes resultados en validaciÃ³n (mejor Ã©poca):

- **mIoU (sin fondo):** ~0.66
- **IoU por clase:**
  - F (Fondo): ~0.97
  - V (Columna): ~0.65
  - T1 (VÃ©rtebra): ~0.66

## ğŸ“Š Ejemplo de Inferencia

A continuaciÃ³n se muestra un ejemplo de los resultados obtenidos con el modelo DeepLabV3+ ResNet50:

### Resultados Visuales

El modelo genera tres visualizaciones:

1. **Imagen Original:** La radiografÃ­a de entrada en escala de grises
2. **MÃ¡scara de SegmentaciÃ³n:** La mÃ¡scara binaria con las clases segmentadas
   - Fondo en negro
   - Columna vertebral (V) en gris oscuro
   - VÃ©rtebra T1 en gris claro
3. **SuperposiciÃ³n:** CombinaciÃ³n de la imagen original con la segmentaciÃ³n
   - **Columna vertebral (V):** Resaltada en **verde**
   - **VÃ©rtebra T1:** Resaltada en **rojo**

### MÃ©tricas de Ejemplo

Para una radiografÃ­a tÃ­pica, el modelo genera las siguientes mÃ©tricas:

#### MÃ©tricas Globales
- **IoU Promedio (Estimado):** 0.8785
- **Dice Promedio (Estimado):** 0.9330
- **Cobertura Foreground:** 9.98%
- **Clases Detectadas:** 3

#### MÃ©tricas por Clase

**V (Columna Vertebral):**
- Porcentaje: 9.54%
- IoU: 0.9669
- Dice: 0.9832
- Confianza: 0.9522

**T1 (VÃ©rtebra T1):**
- Porcentaje: 0.44%
- IoU: 0.7901
- Dice: 0.8828
- Confianza: 0.7462

**F (Fondo):**
- Porcentaje: 90.02%
- IoU: 0.9975
- Dice: 0.9987
- Confianza: 0.9885

#### Promedio (mean)
- IoU: 0.8785
- Dice: 0.9330

### InterpretaciÃ³n

- **Alto IoU y Dice para V:** El modelo segmenta la columna vertebral con alta precisiÃ³n (IoU > 0.96)
- **Buen rendimiento en T1:** A pesar de ser una clase minoritaria, el modelo logra un IoU de ~0.79 para T1
- **Fondo bien identificado:** El fondo se segmenta casi perfectamente (IoU > 0.99)
- **Cobertura realista:** El 9.98% de cobertura foreground refleja la proporciÃ³n real de la columna y T1 en las radiografÃ­as

## ğŸ—ï¸ Estructura del Proyecto

```
columna_vertebra_segmatacion/
â”œâ”€â”€ segmentacion_app/          # AplicaciÃ³n principal
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api.py            # Endpoints de la API
â”‚   â”‚   â”œâ”€â”€ config.py         # ConfiguraciÃ³n
â”‚   â”‚   â”œâ”€â”€ main.py           # AplicaciÃ³n principal
â”‚   â”‚   â”œâ”€â”€ model/            # Modelos ML
â”‚   â”‚   â”‚   â””â”€â”€ segmentation_model.py
â”‚   â”‚   â”œâ”€â”€ schemas/          # Esquemas Pydantic
â”‚   â”‚   â”‚   â””â”€â”€ segmentation.py
â”‚   â”‚   â”œâ”€â”€ static/           # Archivos estÃ¡ticos (imÃ¡genes procesadas)
â”‚   â”‚   â”œâ”€â”€ templates/        # Templates HTML
â”‚   â”‚   â”‚   â””â”€â”€ index.html
â”‚   â”‚   â””â”€â”€ tests/            # Tests
â”‚   â””â”€â”€ requirements.txt      # Dependencias
â”œâ”€â”€ models/                   # Modelos entrenados
â”‚   â”œâ”€â”€ deeplab_densedecoder/ # DeepLabV3++ (Decoder Denso)
â”‚   â”œâ”€â”€ unetplusplus_v2/     # U-Net++ v2
â”‚   â””â”€â”€ deeplab_resnet50/    # DeepLabV3+ ResNet50
â”œâ”€â”€ notebooks/               # Jupyter notebooks de entrenamiento
â”œâ”€â”€ scripts/                 # Scripts de utilidad
â”‚   â”œâ”€â”€ diagnosticos/       # Scripts de diagnÃ³stico
â”‚   â”‚   â”œâ”€â”€ analyze_deeplab_hybrid.py
â”‚   â”‚   â”œâ”€â”€ diagnostico_t1.py
â”‚   â”‚   â””â”€â”€ diagnostico_t1_dense_decoder.py
â”‚   â”œâ”€â”€ tests/              # Scripts de prueba
â”‚   â”‚   â”œâ”€â”€ test_classes.py
â”‚   â”‚   â”œâ”€â”€ test_improvements.py
â”‚   â”‚   â”œâ”€â”€ test_metrics_calculation.py
â”‚   â”‚   â”œâ”€â”€ test_model_loading.py
â”‚   â”‚   â”œâ”€â”€ test_new_model.py
â”‚   â”‚   â””â”€â”€ test_t1_improvement.py
â”‚   â”œâ”€â”€ extract_model.py
â”‚   â”œâ”€â”€ inspect_model.py
â”‚   â”œâ”€â”€ run_server.py
â”‚   â””â”€â”€ setup_ec2.sh
â”œâ”€â”€ Dockerfile               # ConfiguraciÃ³n Docker
â”œâ”€â”€ docker-compose.yml       # OrquestaciÃ³n Docker (opcional)
â”œâ”€â”€ install_dependencies.bat # InstalaciÃ³n Windows
â”œâ”€â”€ install_dependencies.sh  # InstalaciÃ³n Linux/Mac
â”œâ”€â”€ start.bat               # Inicio Windows
â”œâ”€â”€ start.sh                 # Inicio Linux/Mac
â”œâ”€â”€ iniciar_servidor.ps1     # Inicio PowerShell
â”œâ”€â”€ docs/                   # DocumentaciÃ³n y guÃ­as
â”‚   â”œâ”€â”€ GUIA_DESPLIEGUE_EC2.md
â”‚   â”œâ”€â”€ INSTALACION.md
â”‚   â”œâ”€â”€ NOTAS_MODELO.md
â”‚   â””â”€â”€ SOLUCION_PROBLEMAS_UNET.md
â””â”€â”€ README.md               # Este archivo
```

## ğŸ“‹ Requisitos Previos

- **Python:** 3.10 o superior
- **Sistema Operativo:** Windows, Linux o macOS
- **RAM:** MÃ­nimo 4GB (recomendado 8GB+)
- **Espacio en disco:** ~2GB para modelos y dependencias
- **Git LFS:** Requerido para descargar modelos grandes (si usas Git)

## ğŸš€ InstalaciÃ³n Local

### Paso 1: Clonar el Repositorio

```bash
git clone <tu-repositorio-url>
cd columna_vertebra_segmatacion

# Si usas Git LFS (para modelos grandes)
git lfs install
git lfs pull
```

### Paso 2: Crear Entorno Virtual

**Windows (PowerShell):**
```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

**Windows (CMD):**
```cmd
python -m venv venv
venv\Scripts\activate.bat
```

**Linux/Mac:**
```bash
python3 -m venv venv
source venv/bin/activate
```

### Paso 3: Instalar Dependencias

**OpciÃ³n A: Script AutomÃ¡tico (Recomendado)**

**Windows:**
```cmd
install_dependencies.bat
```

**Linux/Mac:**
```bash
chmod +x install_dependencies.sh
./install_dependencies.sh
```

**OpciÃ³n B: Manual**

```bash
# Actualizar pip
pip install --upgrade pip

# Instalar PyTorch (CPU)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu

# Instalar otras dependencias
pip install -r segmentacion_app/requirements.txt
```

**Nota:** Si tienes GPU NVIDIA con CUDA, instala PyTorch con soporte GPU:
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

### Paso 4: Verificar InstalaciÃ³n

```bash
python -c "import torch; print('PyTorch:', torch.__version__)"
python -c "import fastapi; print('FastAPI instalado')"
python -c "import cv2; print('OpenCV:', cv2.__version__)"
```

## ğŸ’» Uso Local

### OpciÃ³n 1: Script de Inicio (Recomendado)

**Windows:**
```cmd
start.bat
```

**Linux/Mac:**
```bash
chmod +x start.sh
./start.sh
```

**PowerShell:**
```powershell
.\iniciar_servidor.ps1
```

### OpciÃ³n 2: Manualmente

```bash
# Activar entorno virtual primero
# Windows: venv\Scripts\activate
# Linux/Mac: source venv/bin/activate

# Ejecutar servidor
uvicorn segmentacion_app.app.main:app --reload --host 0.0.0.0 --port 8000
```

### Acceder a la AplicaciÃ³n

Abre tu navegador en: **http://localhost:8000**

### Verificar que Funciona

**Endpoint de salud:**
```bash
curl http://localhost:8000/api/health
```

DeberÃ­a responder:
```json
{
  "status": "healthy",
  "model_loaded": false,
  "device": "cpu",
  "classes": ["F", "V", "T1"]
}
```

## ğŸ³ Despliegue con Docker

### Requisitos

- Docker instalado
- Docker Compose (opcional, para orquestaciÃ³n)

### OpciÃ³n 1: Docker Simple

**1. Construir la imagen:**
```bash
docker build -t segmentacion-columna .
```

**2. Ejecutar el contenedor:**
```bash
docker run -d \
  --name segmentacion \
  -p 8000:8000 \
  --restart unless-stopped \
  segmentacion-columna
```

**3. Verificar:**
```bash
docker logs -f segmentacion
curl http://localhost:8000/api/health
```

### OpciÃ³n 2: Docker Compose

**1. Crear `docker-compose.yml`:**
```yaml
version: '3.8'

services:
  segmentacion:
    build: .
    container_name: segmentacion-columna
    ports:
      - "8000:8000"
    restart: unless-stopped
    volumes:
      - ./models:/app/models
      - ./segmentacion_app/app/static:/app/segmentacion_app/app/static
    environment:
      - PORT=8000
      - HOST=0.0.0.0
```

**2. Ejecutar:**
```bash
docker-compose up -d
```

**3. Ver logs:**
```bash
docker-compose logs -f
```

### Comandos Ãštiles Docker

```bash
# Ver logs
docker logs -f segmentacion

# Detener
docker stop segmentacion

# Iniciar
docker start segmentacion

# Reiniciar
docker restart segmentacion

# Eliminar contenedor
docker rm segmentacion

# Eliminar imagen
docker rmi segmentacion-columna
```

## â˜ï¸ Despliegue en AWS EC2

### Requisitos Previos

- Instancia EC2 corriendo (Ubuntu 20.04+ recomendado)
- Acceso SSH a la instancia
- Security Group configurado para permitir trÃ¡fico en puerto 8000
- Tipo de instancia: t3.medium o superior (recomendado para modelos grandes)

### OpciÃ³n 1: Despliegue Directo (Sin Docker)

#### Paso 1: Conectar a EC2

```bash
ssh -i tu-key.pem ubuntu@tu-ec2-ip
```

#### Paso 2: Instalar Dependencias del Sistema

```bash
sudo apt update
sudo apt install -y python3-pip python3-venv git git-lfs
```

#### Paso 3: Clonar o Subir el Proyecto

**OpciÃ³n A: Clonar desde Git**
```bash
cd /home/ubuntu
git clone <tu-repositorio-url> columna_vertebra_segmatacion
cd columna_vertebra_segmatacion
git lfs pull  # Descargar modelos grandes
```

**OpciÃ³n B: Subir Archivos con SCP**
```bash
# Desde tu mÃ¡quina local
scp -i tu-key.pem -r columna_vertebra_segmatacion ubuntu@tu-ec2-ip:/home/ubuntu/
```

#### Paso 4: Configurar la AplicaciÃ³n

```bash
cd /home/ubuntu/columna_vertebra_segmatacion

# Crear entorno virtual
python3 -m venv venv
source venv/bin/activate

# Instalar dependencias
pip install --upgrade pip
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
pip install -r segmentacion_app/requirements.txt
```

#### Paso 5: Configurar como Servicio systemd

**Crear archivo de servicio:**
```bash
sudo nano /etc/systemd/system/segmentacion.service
```

**Contenido del archivo:**
```ini
[Unit]
Description=Segmentacion Columna Vertebral API
After=network.target

[Service]
Type=simple
User=ubuntu
WorkingDirectory=/home/ubuntu/columna_vertebra_segmatacion
Environment="PATH=/home/ubuntu/columna_vertebra_segmatacion/venv/bin"
ExecStart=/home/ubuntu/columna_vertebra_segmatacion/venv/bin/uvicorn segmentacion_app.app.main:app --host 0.0.0.0 --port 8000
Restart=always
RestartSec=10
StandardOutput=journal
StandardError=journal

[Install]
WantedBy=multi-user.target
```

**Activar el servicio:**
```bash
sudo systemctl daemon-reload
sudo systemctl enable segmentacion
sudo systemctl start segmentacion
sudo systemctl status segmentacion
```

#### Paso 6: Configurar Security Group

1. Ve a la consola de AWS EC2
2. Selecciona tu instancia
3. Ve a "Security Groups"
4. Edita las reglas de entrada (Inbound rules)
5. Agrega una regla:
   - **Type:** Custom TCP
   - **Port:** 8000
   - **Source:** 0.0.0.0/0 (o tu IP especÃ­fica)
   - **Description:** Segmentacion API

#### Paso 7: Verificar

```bash
# Ver logs
sudo journalctl -u segmentacion -f

# Probar localmente
curl http://localhost:8000/api/health

# Acceder desde Internet
# http://tu-ec2-ip-publica:8000
```

### OpciÃ³n 2: Despliegue con Docker en EC2

#### Paso 1: Instalar Docker

```bash
sudo apt update
sudo apt install -y docker.io docker-compose
sudo usermod -aG docker ubuntu
# Cerrar sesiÃ³n y volver a conectar
```

#### Paso 2: Clonar/Subir Proyecto

```bash
cd /home/ubuntu
git clone <tu-repositorio-url> columna_vertebra_segmatacion
cd columna_vertebra_segmatacion
```

#### Paso 3: Construir y Ejecutar

```bash
docker build -t segmentacion-columna .
docker run -d \
  --name segmentacion \
  -p 8000:8000 \
  --restart unless-stopped \
  segmentacion-columna
```

#### Paso 4: Verificar

```bash
docker logs -f segmentacion
curl http://localhost:8000/api/health
```

### Comandos Ãštiles EC2

```bash
# Gestionar servicio systemd
sudo systemctl status segmentacion
sudo systemctl start segmentacion
sudo systemctl stop segmentacion
sudo systemctl restart segmentacion
sudo journalctl -u segmentacion -f

# Gestionar Docker
docker ps
docker logs -f segmentacion
docker restart segmentacion

# Ver uso de recursos
htop
df -h
free -h
```

## â˜ï¸ Despliegue en Microsoft Azure

### OpciÃ³n 1: Azure App Service

#### Paso 1: Preparar la AplicaciÃ³n

```bash
# Crear archivo .deployment
echo [config] > .deployment
echo SCM_DO_BUILD_DURING_DEPLOYMENT=true >> .deployment

# Crear startup.sh
cat > startup.sh << 'EOF'
#!/bin/bash
cd /home/site/wwwroot
source venv/bin/activate
uvicorn segmentacion_app.app.main:app --host 0.0.0.0 --port 8000
EOF
chmod +x startup.sh
```

#### Paso 2: Desplegar con Azure CLI

```bash
# Instalar Azure CLI
# Windows: https://aka.ms/installazurecliwindows
# Linux: curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash

# Login
az login

# Crear grupo de recursos
az group create --name rg-segmentacion --location eastus

# Crear App Service Plan
az appservice plan create \
  --name plan-segmentacion \
  --resource-group rg-segmentacion \
  --sku B1 \
  --is-linux

# Crear Web App
az webapp create \
  --resource-group rg-segmentacion \
  --plan plan-segmentacion \
  --name segmentacion-columna \
  --runtime "PYTHON:3.10"

# Configurar startup
az webapp config set \
  --resource-group rg-segmentacion \
  --name segmentacion-columna \
  --startup-file "startup.sh"

# Desplegar cÃ³digo
az webapp deployment source config-zip \
  --resource-group rg-segmentacion \
  --name segmentacion-columna \
  --src segmentacion-columna.zip
```

### OpciÃ³n 2: Azure Container Instances (ACI)

#### Paso 1: Construir y Subir Imagen a Azure Container Registry

```bash
# Crear Azure Container Registry
az acr create \
  --resource-group rg-segmentacion \
  --name acrsegmentacion \
  --sku Basic

# Login al ACR
az acr login --name acrsegmentacion

# Construir y subir imagen
az acr build \
  --registry acrsegmentacion \
  --image segmentacion-columna:latest \
  .
```

#### Paso 2: Crear Container Instance

```bash
az container create \
  --resource-group rg-segmentacion \
  --name segmentacion-columna \
  --image acrsegmentacion.azurecr.io/segmentacion-columna:latest \
  --cpu 2 \
  --memory 4 \
  --registry-login-server acrsegmentacion.azurecr.io \
  --registry-username <acr-username> \
  --registry-password <acr-password> \
  --dns-name-label segmentacion-columna \
  --ports 8000
```

### OpciÃ³n 3: Azure Virtual Machine

Similar a EC2, pero con Azure:

```bash
# Crear VM
az vm create \
  --resource-group rg-segmentacion \
  --name vm-segmentacion \
  --image Ubuntu2204 \
  --size Standard_B2s \
  --admin-username azureuser \
  --generate-ssh-keys

# Abrir puerto 8000
az vm open-port \
  --port 8000 \
  --resource-group rg-segmentacion \
  --name vm-segmentacion

# Conectar y seguir pasos de EC2
ssh azureuser@<vm-public-ip>
```

## ğŸŒ Despliegue en Google Cloud Platform (GCP)

### OpciÃ³n 1: Google Cloud Run

#### Paso 1: Preparar Dockerfile

AsegÃºrate de que el Dockerfile estÃ© optimizado para Cloud Run.

#### Paso 2: Construir y Subir Imagen

```bash
# Configurar proyecto
gcloud config set project tu-proyecto-id

# Habilitar APIs
gcloud services enable cloudbuild.googleapis.com
gcloud services enable run.googleapis.com

# Construir y subir
gcloud builds submit --tag gcr.io/tu-proyecto-id/segmentacion-columna

# Desplegar en Cloud Run
gcloud run deploy segmentacion-columna \
  --image gcr.io/tu-proyecto-id/segmentacion-columna \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --memory 2Gi \
  --cpu 2
```

### OpciÃ³n 2: Google Compute Engine (GCE)

Similar a EC2:

```bash
# Crear instancia
gcloud compute instances create segmentacion-vm \
  --zone=us-central1-a \
  --machine-type=n1-standard-2 \
  --image-family=ubuntu-2204-lts \
  --image-project=ubuntu-os-cloud

# Abrir puerto
gcloud compute firewall-rules create allow-segmentacion \
  --allow tcp:8000 \
  --source-ranges 0.0.0.0/0 \
  --description "Allow segmentacion API"

# Conectar y seguir pasos de EC2
gcloud compute ssh segmentacion-vm --zone=us-central1-a
```

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Variables de Entorno

Crea un archivo `.env` (opcional):

```env
HOST=0.0.0.0
PORT=8000
DEBUG=False
MODEL_TYPE=deeplab_resnet50
DEVICE=cpu
```

### ConfiguraciÃ³n de Modelos

Los modelos se configuran en `segmentacion_app/app/config.py`:

```python
AVAILABLE_MODELS = {
    "deeplab_dense_decoder": {...},
    "unetplusplus_v2": {...},
    "deeplab_resnet50": {...}
}
```

### TamaÃ±o de Imagen de Entrada

Modificar en `segmentacion_app/app/config.py`:

```python
INPUT_SIZE = (512, 512)  # Ajustar segÃºn necesidad
```

## ğŸ“¡ API Endpoints

### `GET /`
Interfaz web principal para cargar y segmentar imÃ¡genes.

### `POST /api/segment`
Segmenta una imagen de radiografÃ­a.

**ParÃ¡metros (multipart/form-data):**
- `file`: Archivo de imagen (PNG, JPG, JPEG, DICOM)
- `model_type`: Tipo de modelo (opcional, default: "deeplab_resnet50")
  - Valores: `"deeplab_dense_decoder"`, `"unetplusplus_v2"`, `"deeplab_resnet50"`

**Respuesta:**
```json
{
  "success": true,
  "message": "SegmentaciÃ³n completada exitosamente",
  "model_used": "deeplab_resnet50",
  "original_image_url": "/static/original_xxx.png",
  "segmented_image_url": "/static/mask_xxx.png",
  "overlay_image_url": "/static/overlay_xxx.png",
  "classes_detected": ["F", "V", "T1"],
  "metrics": {
    "mean_iou": 0.1411,
    "mean_dice": 0.0911,
    "foreground_coverage": 9.98,
    "F_percentage": 90.02,
    "F_iou": 1.0000,
    "F_dice": 0.9423,
    "F_confidence": 0.9885,
    "V_percentage": 9.54,
    "V_iou": 0.2724,
    "V_dice": 0.1733,
    "V_confidence": 0.9522,
    "T1_percentage": 0.44,
    "T1_iou": 0.0099,
    "T1_dice": 0.0088,
    "T1_confidence": 0.7462
  }
}
```

### `GET /api/health`
Verifica el estado de la API y modelos.

**ParÃ¡metros de query (opcionales):**
- `model_type`: Tipo de modelo a verificar

**Respuesta:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "device": "cpu",
  "classes": ["F", "V", "T1"],
  "model_type": "deeplab_resnet50"
}
```

## ğŸ“š DocumentaciÃ³n Adicional

Toda la documentaciÃ³n detallada estÃ¡ disponible en la carpeta [`docs/`](docs/):

- **[GuÃ­a de Despliegue EC2](docs/GUIA_DESPLIEGUE_EC2.md)** - GuÃ­a completa paso a paso para AWS EC2
- **[GuÃ­a de InstalaciÃ³n](docs/INSTALACION.md)** - Instrucciones detalladas de instalaciÃ³n
- **[SoluciÃ³n de Problemas](docs/SOLUCION_PROBLEMAS_UNET.md)** - Troubleshooting comÃºn
- **[Notas del Modelo](docs/NOTAS_MODELO.md)** - Notas tÃ©cnicas sobre modelos

## ğŸ› SoluciÃ³n de Problemas

> ğŸ’¡ **MÃ¡s ayuda:** Consulta [docs/SOLUCION_PROBLEMAS_UNET.md](docs/SOLUCION_PROBLEMAS_UNET.md) para problemas especÃ­ficos con modelos U-Net++

### Error: "No module named 'torch._C'"

**SoluciÃ³n:**
```bash
# Desinstalar PyTorch
pip uninstall torch torchvision

# Reinstalar desde Ã­ndice oficial
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
```

### Error: "Weights only load failed"

**SoluciÃ³n:** Ya estÃ¡ manejado en el cÃ³digo. Si persiste, verifica que el archivo del modelo estÃ© completo (descarga con Git LFS).

### Error: "Ran out of input"

**Causa:** Archivo de modelo corrupto o incompleto.

**SoluciÃ³n:**
```bash
# Verificar tamaÃ±o del archivo
ls -lh models/*/*.pth

# Re-descargar con Git LFS
git lfs pull
```

### Error: "ModuleNotFoundError: No module named 'fastapi'"

**SoluciÃ³n:**
```bash
# Activar entorno virtual
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate    # Windows

# Reinstalar dependencias
pip install -r segmentacion_app/requirements.txt
```

### Puerto ya en uso

**SoluciÃ³n:**
```bash
# Cambiar puerto en config.py o usar variable de entorno
export PORT=8001
uvicorn segmentacion_app.app.main:app --port 8001
```

### Error de memoria en EC2

**SoluciÃ³n:**
- Usar instancia con mÃ¡s RAM (t3.large o superior)
- Reducir tamaÃ±o de entrada en `config.py`
- Usar modelo mÃ¡s pequeÃ±o

### Modelo no segmenta correctamente

**Verificar:**
1. Que las clases coincidan: `models/*/classes_*.json`
2. Que el modelo estÃ© completamente descargado
3. Logs del servidor para errores especÃ­ficos

## ğŸ“Š Modelos Disponibles

### DeepLabV3++ (Decoder Denso) - `deeplab_dense_decoder`
- **Arquitectura:** DeepLabV3+ con decoder denso tipo U-Net++
- **CaracterÃ­sticas:** ASPP con atenciÃ³n, decoder de 4 capas, mÃ³dulos de atenciÃ³n
- **Uso:** Balance entre precisiÃ³n y complejidad

### U-Net++ v2 - `unetplusplus_v2`
- **Arquitectura:** U-Net++ optimizada
- **CaracterÃ­sticas:** Skip connections densas, nested pathways
- **Uso:** SegmentaciÃ³n precisa con arquitectura U-Net

### DeepLabV3+ ResNet50 - `deeplab_resnet50`
- **Arquitectura:** DeepLabV3+ estÃ¡ndar de torchvision
- **CaracterÃ­sticas:** Backbone ResNet50, ASPP estÃ¡ndar
- **Uso:** Modelo robusto y probado

## ğŸ”„ Actualizar la AplicaciÃ³n

### Local

```bash
git pull origin main
source venv/bin/activate  # Linux/Mac
pip install -r segmentacion_app/requirements.txt
```

### EC2 (systemd)

```bash
cd /home/ubuntu/columna_vertebra_segmatacion
git pull origin main
source venv/bin/activate
pip install -r segmentacion_app/requirements.txt
sudo systemctl restart segmentacion
```

### Docker

```bash
docker stop segmentacion
docker rm segmentacion
docker build -t segmentacion-columna .
docker run -d -p 8000:8000 --name segmentacion --restart unless-stopped segmentacion-columna
```

## ğŸ“ Notas Importantes

- **Git LFS:** Los modelos grandes estÃ¡n en Git LFS. AsegÃºrate de tenerlo instalado y ejecutar `git lfs pull` despuÃ©s de clonar.
- **Modelos:** Los modelos se cargan bajo demanda. La primera carga puede tardar unos segundos.
- **Memoria:** Los modelos requieren ~2-4GB de RAM. AsegÃºrate de tener suficiente memoria disponible.
- **GPU:** Si tienes GPU NVIDIA, instala PyTorch con soporte CUDA para mejor rendimiento.

## ğŸ“„ Licencia

Este proyecto es para uso acadÃ©mico/investigaciÃ³n.

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:
1. Fork el proyecto
2. Crea una rama para tu feature
3. Commit tus cambios
4. Push a la rama
5. Abre un Pull Request

## ğŸ“§ Contacto

Para preguntas o soporte, abre un issue en el repositorio.
